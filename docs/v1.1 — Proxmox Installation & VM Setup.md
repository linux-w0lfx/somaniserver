# v1.1 – Proxmox Installation and VM Setup

## Objective
Set up Proxmox VE on the server to manage virtual machines.  
This would allow me to run TrueNAS and Ubuntu Server side-by-side, each with dedicated resources.
---

## Hardware at This Stage
| Component  | Details |
|------------|---------|
| CPU        | Intel Core i3-6100T |
| RAM        | 20GB DDR4 |
| Storage    | 500GB HDD (Proxmox OS + local VM storage), 2×2TB HDDs (ZFS mirror passthrough to TrueNAS VM) |
| Network    | Gigabit Ethernet |

---
## Disks Present
- **500GB HDD** – Proxmox OS and local VM storage  
- **2×2TB HDDs** – Reserved for ZFS mirror pool (passed through to TrueNAS VM)  

<img width="1919" height="897" alt="image" src="https://github.com/user-attachments/assets/56c65d59-eb98-478e-8e49-a668797d22ca" />

---

## Installation Process
- Downloaded the latest (**Proxmox VE ISO**)[https://www.proxmox.com/en/downloads] from the official site 
- Booted the server from bootable USB and installed Proxmox to the **500GB HDD** (dedicated as local storage)
- Applied all available updates

<img width="1918" height="905" alt="image" src="https://github.com/user-attachments/assets/7f15f009-838a-48c9-9e99-467c922b2ed5" />

---

## Networking Configuration
- Configured a **Linux bridge (`vmbr0`)** to connect VMs directly to the LAN  
- Assigned the bridge to the server’s primary Ethernet interface  
- Set a static IP for Proxmox to ensure consistent access via web UI  
- Verified remote access from another device using the Proxmox web panel

---

## VM Creation
Two core VMs were provisioned to separate storage management from application hosting:

1. **TrueNAS SCALE VM**
   - **Purpose:** Centralized storage, ZFS pool management, and dataset sharing via NFS
   - Disk: 80GB for installation
   - **Passthrough:** 2×2TB HDDs (raw device passthrough for ZFS mirror pool) 
   - CPU: 1 vCPUs
   - RAM: 5.5GB (currently)
   - Network: Bridged LAN

<img width="1919" height="893" alt="image" src="https://github.com/user-attachments/assets/d4e29aa1-6831-4394-adf3-8873a56b12ae" />

<img width="1919" height="900" alt="image" src="https://github.com/user-attachments/assets/a6f6f70a-588a-40a1-b758-9527d27652a5" />


2. **Ubuntu Server VM**
   - **Purpose:** Host application services like Immich, Nextcloud, and Kasm via Docker
   - Disk: 110GB
   - CPU: 2 vCPUs
   - RAM: 13GB (currently)
   - Network: Bridged LAN

<img width="1919" height="901" alt="image" src="https://github.com/user-attachments/assets/bb181ef7-393e-4516-b78b-d1c287906110" />


---

## Resource Allocation Strategy
The hardware’s **20GB RAM** was split between Proxmox overhead and the two main VMs:
- Proxmox Host: ~1.5GB
- TrueNAS SCALE: 5.5GB
- Ubuntu Server: 13GB

---
## Why Proxmox as Host Instead of Just TrueNAS
Running Proxmox as the main OS and installing TrueNAS + Ubuntu as VMs provides:
- **Flexibility** – Can run other VMs or containers without interfering with storage services  
- **Isolation** – Storage management (TrueNAS) and applications (Ubuntu) are separated, reducing risk from crashes or misconfigurations  
- **Better Resource Control** – RAM/CPU allocation per VM instead of everything going to TrueNAS  
- **Future-Proofing** – Easy to spin up new test environments without touching core services  
- **Easier Backups** – VM snapshots for quick rollbacks before major changes  

--- 
## Verification & Testing
- Both VMs successfully booted and were accessible over LAN  
- Storage and network performance were tested with basic benchmarks  
- Snapshots were not yet configured — will be set up after core services are installed

---

## Version Note
This milestone marks the transition from hardware on a desk to a functional virtualized server environment.
With Proxmox in place, I now have a base that can evolve without wiping the system or breaking storage — the core design principle for somaniserver.
